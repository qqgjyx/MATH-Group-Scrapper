{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T08:04:59.111769Z",
     "start_time": "2024-05-29T08:04:16.013660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract data from a single page\n",
    "def extract_data_from_page(url, page):\n",
    "    params = {\"p\": page}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    data = []\n",
    "    table_rows = soup.find_all('tr')[1:]  # Skip the header row\n",
    "    for row in table_rows:\n",
    "        columns = row.find_all('td')\n",
    "        row_data = []\n",
    "        \n",
    "        # Organism Group\n",
    "        organism_group = columns[0].get_text(strip=True)\n",
    "        row_data.append(organism_group)\n",
    "        \n",
    "        # Name and link\n",
    "        name_tag = columns[1].find('a')\n",
    "        name = name_tag.get_text(strip=True)\n",
    "        name_link = name_tag['href']\n",
    "        row_data.append(name)\n",
    "        row_data.append(name_link)\n",
    "        \n",
    "        # Taxonomy link\n",
    "        taxonomy_tag = columns[2].find('a')\n",
    "        taxonomy_link = taxonomy_tag['href'] if taxonomy_tag else None\n",
    "        row_data.append(taxonomy_link)\n",
    "        \n",
    "        # Growth Media links\n",
    "        growth_media_links = [a['href'] for a in columns[3].find_all('a')]\n",
    "        row_data.append(growth_media_links)\n",
    "        \n",
    "        # External links\n",
    "        external_links = [a['href'] for a in columns[4].find_all('a')]\n",
    "        row_data.append(external_links)\n",
    "        \n",
    "        data.append(row_data)\n",
    "    \n",
    "    return data, soup\n",
    "\n",
    "# Base URL of the webpage\n",
    "base_url = \"https://mediadive.dsmz.de/strains\"\n",
    "all_data = []\n",
    "\n",
    "# Scrape data from the first 20 pages\n",
    "for page in range(1, 21):\n",
    "    # Extract data from the current page\n",
    "    page_data, soup = extract_data_from_page(base_url, page)\n",
    "    all_data.extend(page_data)\n",
    "    \n",
    "    # Print the current page number\n",
    "    print(f\"Processing page {page}\")\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "columns = [\"Organism Group\", \"Name\", \"Name Link\", \"Taxonomy Link\", \"Growth Media Links\", \"External Links\"]\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('dsmz_strains.csv', index=False)\n",
    "\n",
    "print(\"Data scraped and saved to dsmz_strains.csv\")"
   ],
   "id": "de78276f8ea21c8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1\n",
      "Processing page 2\n",
      "Processing page 3\n",
      "Processing page 4\n",
      "Processing page 5\n",
      "Processing page 6\n",
      "Processing page 7\n",
      "Processing page 8\n",
      "Processing page 9\n",
      "Processing page 10\n",
      "Processing page 11\n",
      "Processing page 12\n",
      "Processing page 13\n",
      "Processing page 14\n",
      "Processing page 15\n",
      "Processing page 16\n",
      "Processing page 17\n",
      "Processing page 18\n",
      "Processing page 19\n",
      "Processing page 20\n",
      "Data scraped and saved to dsmz_strains.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e7f9e24231e0f1af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

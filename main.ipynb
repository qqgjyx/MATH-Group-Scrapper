{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:40:53.776534Z",
     "start_time": "2024-05-29T19:40:53.772834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ],
   "id": "de78276f8ea21c8b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:41:00.112246Z",
     "start_time": "2024-05-29T19:41:00.109891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Base URL of the webpage\n",
    "base_url = \"https://mediadive.dsmz.de\""
   ],
   "id": "2cf409d0c5caa8b6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:41:06.661331Z",
     "start_time": "2024-05-29T19:41:06.658191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data_from_page(url, page):\n",
    "    params = {\"p\": page}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    data = []\n",
    "    table_rows = soup.find_all('tr')[1:]  # Skip the header row\n",
    "    for row in table_rows:\n",
    "        columns = row.find_all('td')\n",
    "        row_data = []\n",
    "        \n",
    "        # Organism Group\n",
    "        organism_group = columns[0].get_text(strip=True)\n",
    "        row_data.append(organism_group)\n",
    "        \n",
    "        # Name and link\n",
    "        name_tag = columns[1].find('a')\n",
    "        name = name_tag.get_text(strip=True)\n",
    "        name_link = base_url + name_tag['href']\n",
    "        row_data.append(name)\n",
    "        row_data.append(name_link)\n",
    "        \n",
    "        # Taxonomy link\n",
    "        taxonomy_tag = columns[2].find('a')\n",
    "        taxonomy_link = base_url + taxonomy_tag['href'] if taxonomy_tag else None\n",
    "        row_data.append(taxonomy_link)\n",
    "        \n",
    "        # Growth Media links\n",
    "        growth_media_links = [base_url + a['href'] for a in columns[3].find_all('a')]\n",
    "        row_data.append(growth_media_links)\n",
    "        \n",
    "        # External links\n",
    "        external_links = [a['href'] for a in columns[4].find_all('a')]\n",
    "        row_data.append(external_links)\n",
    "        \n",
    "        data.append(row_data)\n",
    "    \n",
    "    return data, soup"
   ],
   "id": "e7f9e24231e0f1af",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:41:13.660371Z",
     "start_time": "2024-05-29T19:41:13.658336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to fetch and print the HTML structure of a given URL\n",
    "def fetch_html_structure(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching HTML content from {url}: {e}\")\n",
    "        return None"
   ],
   "id": "f4b44818ee04a863",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:41:23.482256Z",
     "start_time": "2024-05-29T19:41:23.478270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract key data from the HTML structure\n",
    "def extract_key_data(soup):\n",
    "    if not soup:\n",
    "        return None\n",
    "    \n",
    "    # Extracting the title\n",
    "    title = soup.find('title').text.strip() if soup.find('title') else 'N/A'\n",
    "\n",
    "    # Extracting the strain name\n",
    "    strain_name = soup.find('h2').text.strip() if soup.find('h2') else 'N/A'\n",
    "\n",
    "    # Extracting the synonyms\n",
    "    synonyms = []\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for p in paragraphs:\n",
    "        bold_text = p.find('b', string='Synonyms:')\n",
    "        if bold_text:\n",
    "            for content in p.contents:\n",
    "                if content.name == 'a':\n",
    "                    synonyms.append(content.get_text(strip=True))\n",
    "                    synonyms.append('href: '+content.get('href'))\n",
    "                elif isinstance(content, str) and content.strip():\n",
    "                    synonyms.extend(content.split(', '))\n",
    "            break\n",
    "    \n",
    "    # Extracting growth media details\n",
    "    media_details = []\n",
    "    media_boxes = soup.find_all('div', class_='box')\n",
    "\n",
    "    for box in media_boxes:\n",
    "        media_title = box.find('h3', class_='title').text.strip() if box.find('h3', class_='title') else 'N/A'\n",
    "        media_link = box.find('a', class_='link colorless')['href'] if box.find('a', 'link colorless') else 'N/A'\n",
    "        \n",
    "        # Corrected logic to check for growth observation\n",
    "        growth_observed = 'Yes' if box.find('i', class_='ph ph-lg ph-check text-success') else 'No'\n",
    "        \n",
    "        growth_conditions = box.find('span', class_='badge danger').text.strip() if box.find('span', 'badge danger') else 'N/A'\n",
    "        \n",
    "        media_details.append({\n",
    "            'media_title': media_title,\n",
    "            'media_link': media_link,\n",
    "            'growth_observed': growth_observed,\n",
    "            'growth_conditions': growth_conditions\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'title': title,\n",
    "        'strain_name': strain_name,\n",
    "        'synonyms': synonyms,\n",
    "        'media_details': media_details\n",
    "    }"
   ],
   "id": "591bcabce2ced0ba",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:41:34.378723Z",
     "start_time": "2024-05-29T19:41:34.376980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract detailed strain information\n",
    "def extract_strain_details(url):\n",
    "    soup = fetch_html_structure(url)\n",
    "    return extract_key_data(soup)"
   ],
   "id": "b685551939bab512",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:41:40.961212Z",
     "start_time": "2024-05-29T19:41:40.957967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract medium information\n",
    "def extract_medium_details(url):\n",
    "    retries = 3\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            medium_details = {}\n",
    "            # Extract medium name and components\n",
    "            medium_details['Medium Name'] = soup.find('h1').get_text(strip=True)\n",
    "            medium_details['Components'] = {item.find('span', class_='compound-name').get_text(strip=True): item.find('span', class_='compound-amount').get_text(strip=True) for item in soup.find_all('div', class_='compound')}\n",
    "            return medium_details\n",
    "        except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
    "            print(f\"Error fetching medium details from {url}: {e}. Retrying ({i+1}/{retries})...\")\n",
    "            time.sleep(5)\n",
    "    return {\"Medium Name\": \"\", \"Components\": {}}"
   ],
   "id": "7daeb30dd6b7e029",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:51:24.987409Z",
     "start_time": "2024-05-29T19:50:44.299178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main scraping process\n",
    "all_data = []\n",
    "\n",
    "# Scrape data from the first 20 pages\n",
    "for page in range(1, 21):\n",
    "    try:\n",
    "        # Extract data from the current page\n",
    "        page_data, soup = extract_data_from_page(base_url + \"/strains\", page)\n",
    "        all_data.extend(page_data)\n",
    "        \n",
    "        # Print the current page number\n",
    "        print(f\"Processing page {page}\")\n",
    "    except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
    "        print(f\"Error fetching data from page {page}: {e}. Skipping this page...\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "columns = [\"Organism Group\", \"Name\", \"Name Link\", \"Taxonomy Link\", \"Growth Media Links\", \"External Links\"]\n",
    "df = pd.DataFrame(all_data, columns=columns)"
   ],
   "id": "481ed68258a2ef01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1\n",
      "Processing page 2\n",
      "Processing page 3\n",
      "Processing page 4\n",
      "Processing page 5\n",
      "Processing page 6\n",
      "Processing page 7\n",
      "Processing page 8\n",
      "Processing page 9\n",
      "Processing page 10\n",
      "Processing page 11\n",
      "Processing page 12\n",
      "Processing page 13\n",
      "Processing page 14\n",
      "Processing page 15\n",
      "Processing page 16\n",
      "Processing page 17\n",
      "Processing page 18\n",
      "Processing page 19\n",
      "Processing page 20\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:44:15.427403Z",
     "start_time": "2024-05-29T19:42:01.580966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract detailed information for each strain and medium\n",
    "detailed_data = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Extracting strain details\"):\n",
    "    strain_details = extract_strain_details(row['Name Link'])\n",
    "    if strain_details:\n",
    "        for medium_link in tqdm(row['Growth Media Links'], desc=f\"Extracting media for {row['Name']}\", leave=False):\n",
    "            medium_details = extract_medium_details(medium_link)\n",
    "            detailed_data.append({\n",
    "                \"Organism Group\": row['Organism Group'],\n",
    "                \"Name\": row['Name'],\n",
    "                \"Synonyms\": ', '.join(strain_details['synonyms']),\n",
    "                \"Growth Conditions\": strain_details['media_details'],\n",
    "                \"Medium Name\": medium_details['Medium Name'],\n",
    "                \"Components\": medium_details['Components']\n",
    "            })\n",
    "    # Save progress periodically\n",
    "    if (index + 1) % 10 == 0:\n",
    "        df_detailed = pd.DataFrame(detailed_data)\n",
    "        df_detailed.to_csv('dsmz_detailed_strains_partial.csv', index=False)"
   ],
   "id": "b51a2247d4d683e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting strain details:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Extracting media for Heyndrickxia coagulans DSM 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Heyndrickxia coagulans DSM 1:  33%|███▎      | 1/3 [00:01<00:03,  1.98s/it]\u001B[A\n",
      "Extracting media for Heyndrickxia coagulans DSM 1:  67%|██████▋   | 2/3 [00:04<00:02,  2.46s/it]\u001B[A\n",
      "Extracting media for Heyndrickxia coagulans DSM 1: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]\u001B[A\n",
      "Extracting strain details:   5%|▌         | 1/20 [00:08<02:44,  8.68s/it]                       \u001B[A\n",
      "Extracting media for Paenibacillus macquariensis subsp. macquariensis DSM 2:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Paenibacillus macquariensis subsp. macquariensis DSM 2: 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\u001B[A\n",
      "Extracting strain details:  10%|█         | 2/20 [00:13<01:52,  6.24s/it]                                                 \u001B[A\n",
      "Extracting media for Sporosarcina psychrophila DSM 3:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Sporosarcina psychrophila DSM 3:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]\u001B[A\n",
      "Extracting media for Sporosarcina psychrophila DSM 3: 100%|██████████| 2/2 [00:05<00:00,  2.65s/it]\u001B[A\n",
      "Extracting strain details:  15%|█▌        | 3/20 [00:20<01:52,  6.64s/it]                          \u001B[A\n",
      "Extracting media for Sporosarcina globispora DSM 4:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Sporosarcina globispora DSM 4:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]\u001B[A\n",
      "Extracting media for Sporosarcina globispora DSM 4: 100%|██████████| 2/2 [00:05<00:00,  2.61s/it]\u001B[A\n",
      "Extracting strain details:  20%|██        | 4/20 [00:27<01:48,  6.80s/it]                        \u001B[A\n",
      "Extracting media for Psychrobacillus insolitus DSM 5:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Psychrobacillus insolitus DSM 5: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\u001B[A\n",
      "Extracting strain details:  25%|██▌       | 5/20 [00:31<01:28,  5.88s/it]                          \u001B[A\n",
      "Extracting media for Peribacillus psychrosaccharolyticus DSM 6:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Peribacillus psychrosaccharolyticus DSM 6:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]\u001B[A\n",
      "Extracting media for Peribacillus psychrosaccharolyticus DSM 6: 100%|██████████| 2/2 [00:05<00:00,  2.75s/it]\u001B[A\n",
      "Extracting strain details:  30%|███       | 6/20 [00:38<01:28,  6.35s/it]                                    \u001B[A\n",
      "Extracting media for Bacillus amyloliquefaciens DSM 7:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Bacillus amyloliquefaciens DSM 7: 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\u001B[A\n",
      "Extracting strain details:  35%|███▌      | 7/20 [00:43<01:14,  5.76s/it]                           \u001B[A\n",
      "Extracting media for Lederbergia lenta DSM 9:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Lederbergia lenta DSM 9:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]\u001B[A\n",
      "Extracting media for Lederbergia lenta DSM 9: 100%|██████████| 2/2 [00:05<00:00,  2.71s/it]\u001B[A\n",
      "Extracting strain details:  40%|████      | 8/20 [00:50<01:14,  6.21s/it]                  \u001B[A\n",
      "Extracting media for Bacillus subtilis DSM 10:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Bacillus subtilis DSM 10:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]\u001B[A\n",
      "Extracting media for Bacillus subtilis DSM 10: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]\u001B[A\n",
      "Extracting strain details:  45%|████▌     | 9/20 [00:57<01:10,  6.41s/it]                   \u001B[A\n",
      "Extracting media for Niallia circulans DSM 11:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Niallia circulans DSM 11:  33%|███▎      | 1/3 [00:02<00:05,  2.89s/it]\u001B[A\n",
      "Extracting media for Niallia circulans DSM 11:  67%|██████▋   | 2/3 [00:06<00:03,  3.05s/it]\u001B[A\n",
      "Extracting media for Niallia circulans DSM 11: 100%|██████████| 3/3 [00:08<00:00,  2.73s/it]\u001B[A\n",
      "Extracting strain details:  50%|█████     | 10/20 [01:07<01:15,  7.55s/it]                  \u001B[A\n",
      "Extracting media for Cytobacillus firmus DSM 12:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Cytobacillus firmus DSM 12:  50%|█████     | 1/2 [00:02<00:02,  2.92s/it]\u001B[A\n",
      "Extracting media for Cytobacillus firmus DSM 12: 100%|██████████| 2/2 [00:05<00:00,  2.65s/it]\u001B[A\n",
      "Extracting strain details:  55%|█████▌    | 11/20 [01:14<01:06,  7.37s/it]                    \u001B[A\n",
      "Extracting media for Bacillus licheniformis DSM 13:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Bacillus licheniformis DSM 13:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]\u001B[A\n",
      "Extracting media for Bacillus licheniformis DSM 13: 100%|██████████| 2/2 [00:05<00:00,  2.49s/it]\u001B[A\n",
      "Extracting strain details:  60%|██████    | 12/20 [01:21<00:57,  7.18s/it]                       \u001B[A\n",
      "Extracting media for Bacillus sp. DSM 14:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Bacillus sp. DSM 14: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\u001B[A\n",
      "Extracting strain details:  65%|██████▌   | 13/20 [01:25<00:44,  6.33s/it]             \u001B[A\n",
      "Extracting media for Bacillus licheniformis DSM 15:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Bacillus licheniformis DSM 15: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\u001B[A\n",
      "Extracting strain details:  70%|███████   | 14/20 [01:30<00:34,  5.77s/it]                       \u001B[A\n",
      "Extracting media for Geobacillus stearothermophilus DSM 22:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Geobacillus stearothermophilus DSM 22:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]\u001B[A\n",
      "Extracting media for Geobacillus stearothermophilus DSM 22: 100%|██████████| 2/2 [00:05<00:00,  2.66s/it]\u001B[A\n",
      "Extracting strain details:  75%|███████▌  | 15/20 [01:37<00:31,  6.25s/it]                               \u001B[A\n",
      "Extracting media for Bacillus badius DSM 23:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Bacillus badius DSM 23:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]\u001B[A\n",
      "Extracting media for Bacillus badius DSM 23: 100%|██████████| 2/2 [00:05<00:00,  2.58s/it]\u001B[A\n",
      "Extracting strain details:  80%|████████  | 16/20 [01:44<00:25,  6.46s/it]                \u001B[A\n",
      "Extracting media for Paenibacillus macerans DSM 24:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Paenibacillus macerans DSM 24:  33%|███▎      | 1/3 [00:02<00:05,  2.75s/it]\u001B[A\n",
      "Extracting media for Paenibacillus macerans DSM 24:  67%|██████▋   | 2/3 [00:05<00:02,  2.56s/it]\u001B[A\n",
      "Extracting media for Paenibacillus macerans DSM 24: 100%|██████████| 3/3 [00:07<00:00,  2.43s/it]\u001B[A\n",
      "Extracting strain details:  85%|████████▌ | 17/20 [01:53<00:21,  7.29s/it]                       \u001B[A\n",
      "Extracting media for Brevibacillus laterosporus DSM 25:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Brevibacillus laterosporus DSM 25:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]\u001B[A\n",
      "Extracting media for Brevibacillus laterosporus DSM 25: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]\u001B[A\n",
      "Extracting strain details:  90%|█████████ | 18/20 [02:00<00:14,  7.18s/it]                           \u001B[A\n",
      "Extracting media for Virgibacillus pantothenticus DSM 26:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Virgibacillus pantothenticus DSM 26:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]\u001B[A\n",
      "Extracting media for Virgibacillus pantothenticus DSM 26: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]\u001B[A\n",
      "Extracting strain details:  95%|█████████▌| 19/20 [02:07<00:07,  7.02s/it]                             \u001B[A\n",
      "Extracting media for Bacillus pumilus DSM 27:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Extracting media for Bacillus pumilus DSM 27:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]\u001B[A\n",
      "Extracting media for Bacillus pumilus DSM 27: 100%|██████████| 2/2 [00:05<00:00,  2.50s/it]\u001B[A\n",
      "Extracting strain details: 100%|██████████| 20/20 [02:13<00:00,  6.69s/it]                 \u001B[A\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T19:44:20.412968Z",
     "start_time": "2024-05-29T19:44:20.408927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a detailed DataFrame\n",
    "df_detailed = pd.DataFrame(detailed_data)\n",
    "\n",
    "# Save the detailed DataFrame to a CSV file\n",
    "df_detailed.to_csv('dsmz_detailed_strains.csv', index=False)\n",
    "\n",
    "print(\"Detailed data scraped and saved to dsmz_detailed_strains.csv\")"
   ],
   "id": "55f518bc34aa7013",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed data scraped and saved to dsmz_detailed_strains.csv\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "738e18c8e8f3d150"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:48:37.207085Z",
     "start_time": "2024-05-31T13:48:36.843309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ],
   "id": "c155a4ec5ab3c40d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data from pages: 100%|██████████| 20/20 [00:05<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "\n",
    "# Base URL of the webpage\n",
    "base_url = \"https://mediadive.dsmz.de\"\n",
    "\n",
    "# Function to extract data from a single page\n",
    "def extract_data_from_page(url, page, retries=5):\n",
    "    params = {\"p\": page}\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            data = []\n",
    "            table_rows = soup.find_all('tr')[1:]  # Skip the header row\n",
    "            for row in table_rows:\n",
    "                columns = row.find_all('td')\n",
    "                row_data = [page]  # Add the page number\n",
    "                \n",
    "                # Organism Group\n",
    "                organism_group = columns[0].get_text(strip=True)\n",
    "                row_data.append(organism_group)\n",
    "                \n",
    "                # Name and link\n",
    "                name_tag = columns[1].find('a')\n",
    "                name = name_tag.get_text(strip=True)\n",
    "                name_link = base_url + name_tag['href']\n",
    "                row_data.append(name)\n",
    "                row_data.append(name_link)\n",
    "                \n",
    "                # Taxonomy link\n",
    "                taxonomy_tag = columns[2].find('a')\n",
    "                taxonomy_link = base_url + taxonomy_tag['href'] if taxonomy_tag else None\n",
    "                row_data.append(taxonomy_link)\n",
    "                \n",
    "                # Growth Media links\n",
    "                growth_media = [a.get_text(strip=True) for a in columns[3].find_all('a')]\n",
    "                growth_media_links = [base_url + a['href'] for a in columns[3].find_all('a')]\n",
    "                row_data.append(growth_media)\n",
    "                row_data.append(growth_media_links)\n",
    "                \n",
    "                # External links\n",
    "                external_links = [a['href'] for a in columns[4].find_all('a')]\n",
    "                row_data.append(external_links)\n",
    "                \n",
    "                data.append(row_data)\n",
    "            \n",
    "            return data\n",
    "        except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
    "            print(f\"Error fetching page {page}: {e}. Retrying {attempt + 1}/{retries}...\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "    return []\n",
    "\n",
    "# Main scraping process\n",
    "all_data = []\n",
    "num_pages = 20  # Adjust the number of pages you want to scrape\n",
    "\n",
    "max_workers = 16  # Adjust based on the MacBook M3 Pro capabilities\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_to_page = {executor.submit(extract_data_from_page, base_url + \"/strains\", page): page for page in range(1, num_pages + 1)}\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_page), total=num_pages, desc=\"Extracting data from pages\"):\n",
    "        page_data = future.result()\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "# Sort the data based on the page number to maintain the order\n",
    "all_data.sort(key=lambda x: x[0])\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "columns = [\"Page\", \"Organism Group\", \"Name\", \"Name Link\", \"Taxonomy Link\", \"Growth media\", \"Growth Media Links\", \"External Links\"]\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "df.drop(columns=[\"Page\"], inplace=True)  # Remove the page column if not needed\n",
    "df.to_csv('initial_dsmz_data.csv', index=False)\n",
    "\n",
    "# Load the initial data\n",
    "df = pd.read_csv('initial_dsmz_data.csv')"
   ],
   "id": "e8962c658411e068"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T05:49:53.930299Z",
     "start_time": "2024-05-31T05:48:35.617786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to fetch HTML content and parse it with BeautifulSoup\n",
    "def fetch_html_structure(url, retries=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            return soup\n",
    "        except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
    "            print(f\"Error fetching HTML content from {url}: {e}. Retrying {attempt + 1}/{retries}...\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "    return None\n",
    "\n",
    "# Function to extract key data from the parsed HTML content\n",
    "def extract_key_data(soup):\n",
    "    if not soup:\n",
    "        return None\n",
    "    \n",
    "    title = soup.find('title').text.strip() if soup.find('title') else 'N/A'\n",
    "    strain_name = soup.find('h2').text.strip() if soup.find('h2') else 'N/A'\n",
    "    synonyms = []\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for p in paragraphs:\n",
    "        bold_text = p.find('b', string='Synonyms:')\n",
    "        if bold_text:\n",
    "            for content in p.contents:\n",
    "                if content.name == 'a':\n",
    "                    synonyms.append(content.get_text(strip=True))\n",
    "                    synonyms.append('href: ' + content.get('href'))\n",
    "                elif isinstance(content, str) and content.strip():\n",
    "                    synonyms.extend(content.split(', '))\n",
    "            break\n",
    "    \n",
    "    media_details = []\n",
    "    media_boxes = soup.find_all('div', class_='box')\n",
    "    for box in media_boxes:\n",
    "        media_title = box.find('h3', class_='title').text.strip() if box.find('h3', 'title') else 'N/A'\n",
    "        media_link = box.find('a', class_='link colorless')['href'] if box.find('a', 'link colorless') else 'N/A'\n",
    "        growth_observed = 'Yes' if box.find('i', class_='ph ph-lg ph-check text-success') else 'No'\n",
    "        growth_conditions = box.find('span', class_='badge danger').text.strip() if box.find('span', 'badge danger') else 'N/A'\n",
    "        \n",
    "        media_details.append({\n",
    "            'media_title': media_title,\n",
    "            'media_link': media_link,\n",
    "            'growth_observed': growth_observed,\n",
    "            'growth_conditions': growth_conditions\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'title': title,\n",
    "        'strain_name': strain_name,\n",
    "        'synonyms': synonyms,\n",
    "        'media_details': media_details\n",
    "    }\n",
    "\n",
    "# Function to extract strain details from a row of the DataFrame\n",
    "def extract_strain_details(row):\n",
    "    url = row['Name Link']\n",
    "    soup = fetch_html_structure(url)\n",
    "    return extract_key_data(soup)\n",
    "\n",
    "# Function to save detailed data incrementally\n",
    "def save_detailed_data(detailed_data):\n",
    "    df_detailed = pd.DataFrame(detailed_data)\n",
    "    df_detailed.to_csv('detailed_dsmz_data.csv', index=False)\n",
    "\n",
    "# Load the initial DataFrame (assuming it's loaded in variable df)\n",
    "# df = pd.read_csv('initial_data.csv')  # Load your initial DataFrame here\n",
    "\n",
    "# Initialize an empty list to hold detailed data\n",
    "detailed_data = []\n",
    "num_strains = df.shape[0]\n",
    "max_workers = 10  # Adjust the number of workers as needed\n",
    "\n",
    "# Extract detailed information for each strain with ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_to_index = {executor.submit(extract_strain_details, row): index for index, row in df.iterrows()}\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_index), total=num_strains, desc=\"Extracting strain details\"):\n",
    "        index = future_to_index[future]\n",
    "        strain_details = future.result()\n",
    "        if strain_details:\n",
    "            detailed_data.append({\n",
    "                \"Name\": df.loc[index, 'Name'],\n",
    "                \"Synonyms\": ', '.join(strain_details['synonyms']),\n",
    "                \"Growth Conditions\": strain_details['media_details']\n",
    "            })\n",
    "            # Save incrementally after each strain is processed\n",
    "            save_detailed_data(detailed_data)\n",
    "\n",
    "# Sort the detailed data based on the Name to maintain order\n",
    "detailed_data.sort(key=lambda x: int(x['Name'].split(' ')[-1]))\n",
    "\n",
    "# Create the final detailed DataFrame\n",
    "df_detailed = pd.DataFrame(detailed_data)\n",
    "df_detailed.to_csv('detailed_dsmz_data.csv', index=False)\n",
    "\n",
    "print(\"Detailed data saved to detailed_dsmz_data.csv\")"
   ],
   "id": "6d8035eda2da9aef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting strain details:  17%|█▋        | 68/400 [00:13<01:05,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching HTML content from https://mediadive.dsmz.de/strains/view/DSM 84: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')). Retrying 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting strain details:  66%|██████▌   | 262/400 [00:51<00:15,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching HTML content from https://mediadive.dsmz.de/strains/view/DSM 389: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')). Retrying 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting strain details:  90%|████████▉ | 358/400 [01:10<00:09,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching HTML content from https://mediadive.dsmz.de/strains/view/DSM 518: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')). Retrying 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting strain details: 100%|██████████| 400/400 [01:18<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed data saved to detailed_dsmz_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T05:51:00.111557Z",
     "start_time": "2024-05-31T05:51:00.048963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the detailed data\n",
    "df_detailed = pd.read_csv('detailed_dsmz_data.csv')\n",
    "\n",
    "# Merge the initial and detailed DataFrames with progress bar\n",
    "merged_data = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Merging data\"):\n",
    "    detailed_row = df_detailed[df_detailed['Name'] == row['Name']]\n",
    "    if not detailed_row.empty:\n",
    "        merged_row = {**row.to_dict(), **detailed_row.iloc[0].to_dict()}\n",
    "    else:\n",
    "        merged_row = row.to_dict()\n",
    "    merged_data.append(merged_row)\n",
    "\n",
    "# Convert the merged data to a DataFrame and save it\n",
    "merged_data.sort(key=lambda x: int(x['Name'].split(' ')[-1]))\n",
    "merged_df = pd.DataFrame(merged_data)\n",
    "merged_df.to_csv('merged_dsmz_strains.csv', index=False)\n",
    "\n",
    "print(\"Merged data saved to merged_dsmz_strains.csv\")"
   ],
   "id": "db0afc6e25a947a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging data: 100%|██████████| 400/400 [00:00<00:00, 8012.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to merged_dsmz_strains.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:49:52.273119Z",
     "start_time": "2024-05-31T13:48:41.441212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('initial_dsmz_data.csv')\n",
    "df_detailed = pd.read_csv('detailed_dsmz_data.csv')\n",
    "\n",
    "# Merge the initial and detailed DataFrames with progress bar\n",
    "merged_data = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Merging data\"):\n",
    "    detailed_row = df_detailed[df_detailed['Name'] == row['Name']]\n",
    "    if not detailed_row.empty:\n",
    "        merged_row = {**row.to_dict(), **detailed_row.iloc[0].to_dict()}\n",
    "    else:\n",
    "        merged_row = row.to_dict()\n",
    "    merged_data.append(merged_row)\n",
    "    \n",
    "merged_df = pd.DataFrame(merged_data)\n",
    "\n",
    "merged_df"
   ],
   "id": "ebc97064c5d08671",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging data: 100%|██████████| 46242/46242 [01:10<00:00, 655.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      Organism Group                                               Name  \\\n",
       "0          Bacterium                       Heyndrickxia coagulans DSM 1   \n",
       "1          Bacterium  Paenibacillus macquariensis subsp. macquariens...   \n",
       "2          Bacterium                    Sporosarcina psychrophila DSM 3   \n",
       "3          Bacterium                      Sporosarcina globispora DSM 4   \n",
       "4          Bacterium                    Psychrobacillus insolitus DSM 5   \n",
       "...              ...                                                ...   \n",
       "46237            NaN                          Phage (phagum) DSM 117437   \n",
       "46238            NaN                          Phage (phagum) DSM 117679   \n",
       "46239            NaN                          Phage (phagum) DSM 117680   \n",
       "46240            NaN              Staphylococcus epidermidis DSM 117681   \n",
       "46241            NaN              Staphylococcus epidermidis DSM 117682   \n",
       "\n",
       "                                               Name Link  \\\n",
       "0           https://mediadive.dsmz.de/strains/view/DSM 1   \n",
       "1           https://mediadive.dsmz.de/strains/view/DSM 2   \n",
       "2           https://mediadive.dsmz.de/strains/view/DSM 3   \n",
       "3           https://mediadive.dsmz.de/strains/view/DSM 4   \n",
       "4           https://mediadive.dsmz.de/strains/view/DSM 5   \n",
       "...                                                  ...   \n",
       "46237  https://mediadive.dsmz.de/strains/view/DSM 117437   \n",
       "46238  https://mediadive.dsmz.de/strains/view/DSM 117679   \n",
       "46239  https://mediadive.dsmz.de/strains/view/DSM 117680   \n",
       "46240  https://mediadive.dsmz.de/strains/view/DSM 117681   \n",
       "46241  https://mediadive.dsmz.de/strains/view/DSM 117682   \n",
       "\n",
       "                                           Taxonomy Link         Growth media  \\\n",
       "0      https://mediadive.dsmz.de/taxonomy?level=speci...  ['453', '1', 'J22']   \n",
       "1      https://mediadive.dsmz.de/taxonomy?level=speci...                ['1']   \n",
       "2      https://mediadive.dsmz.de/taxonomy?level=speci...         ['1', 'J22']   \n",
       "3      https://mediadive.dsmz.de/taxonomy?level=speci...       ['514', 'J22']   \n",
       "4      https://mediadive.dsmz.de/taxonomy?level=speci...              ['123']   \n",
       "...                                                  ...                  ...   \n",
       "46237                                                NaN              ['381']   \n",
       "46238                                                NaN               ['92']   \n",
       "46239                                                NaN               ['92']   \n",
       "46240                                                NaN               ['92']   \n",
       "46241                                                NaN               ['92']   \n",
       "\n",
       "                                      Growth Media Links  \\\n",
       "0      ['https://mediadive.dsmz.de/medium/453', 'http...   \n",
       "1                 ['https://mediadive.dsmz.de/medium/1']   \n",
       "2      ['https://mediadive.dsmz.de/medium/1', 'https:...   \n",
       "3      ['https://mediadive.dsmz.de/medium/514', 'http...   \n",
       "4               ['https://mediadive.dsmz.de/medium/123']   \n",
       "...                                                  ...   \n",
       "46237           ['https://mediadive.dsmz.de/medium/381']   \n",
       "46238            ['https://mediadive.dsmz.de/medium/92']   \n",
       "46239            ['https://mediadive.dsmz.de/medium/92']   \n",
       "46240            ['https://mediadive.dsmz.de/medium/92']   \n",
       "46241            ['https://mediadive.dsmz.de/medium/92']   \n",
       "\n",
       "                                          External Links  \\\n",
       "0      ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "1      ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "2      ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "3      ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "4      ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "...                                                  ...   \n",
       "46237  ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "46238  ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "46239  ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "46240  ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "46241  ['https://www.dsmz.de/collection/catalogue/det...   \n",
       "\n",
       "                                                Synonyms  \\\n",
       "0      \\r\\n        ATCC 7050, BCRC 10606, CCM 2013, C...   \n",
       "1      \\r\\n        ATCC 23464, CCUG 37394, CIP 103269...   \n",
       "2      \\r\\n        ATCC 23304, BCRC 11738, CCM 2117, ...   \n",
       "3      \\r\\n        ATCC 23301, CCM 2119, CCUG 7419, C...   \n",
       "4      \\r\\n        ATCC 23299, CCM 2175, CCUG 7420, ,...   \n",
       "...                                                  ...   \n",
       "46237                                                NaN   \n",
       "46238                                                NaN   \n",
       "46239                                                NaN   \n",
       "46240                                                NaN   \n",
       "46241                                                NaN   \n",
       "\n",
       "                                       Growth Conditions  \n",
       "0      [{'media_title': '1: NUTRIENT AGAR', 'media_li...  \n",
       "1      [{'media_title': '1: NUTRIENT AGAR', 'media_li...  \n",
       "2      [{'media_title': '1: NUTRIENT AGAR', 'media_li...  \n",
       "3      [{'media_title': '514: BACTO MARINE BROTH (DIF...  \n",
       "4      [{'media_title': '123: MARINE AGAR', 'media_li...  \n",
       "...                                                  ...  \n",
       "46237  [{'media_title': '381: LB (Luria-Bertani) MEDI...  \n",
       "46238  [{'media_title': '92: TRYPTICASE SOY YEAST EXT...  \n",
       "46239  [{'media_title': '92: TRYPTICASE SOY YEAST EXT...  \n",
       "46240  [{'media_title': '92: TRYPTICASE SOY YEAST EXT...  \n",
       "46241  [{'media_title': '92: TRYPTICASE SOY YEAST EXT...  \n",
       "\n",
       "[46242 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organism Group</th>\n",
       "      <th>Name</th>\n",
       "      <th>Name Link</th>\n",
       "      <th>Taxonomy Link</th>\n",
       "      <th>Growth media</th>\n",
       "      <th>Growth Media Links</th>\n",
       "      <th>External Links</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>Growth Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bacterium</td>\n",
       "      <td>Heyndrickxia coagulans DSM 1</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 1</td>\n",
       "      <td>https://mediadive.dsmz.de/taxonomy?level=speci...</td>\n",
       "      <td>['453', '1', 'J22']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/453', 'http...</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>\\r\\n        ATCC 7050, BCRC 10606, CCM 2013, C...</td>\n",
       "      <td>[{'media_title': '1: NUTRIENT AGAR', 'media_li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bacterium</td>\n",
       "      <td>Paenibacillus macquariensis subsp. macquariens...</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 2</td>\n",
       "      <td>https://mediadive.dsmz.de/taxonomy?level=speci...</td>\n",
       "      <td>['1']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/1']</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>\\r\\n        ATCC 23464, CCUG 37394, CIP 103269...</td>\n",
       "      <td>[{'media_title': '1: NUTRIENT AGAR', 'media_li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bacterium</td>\n",
       "      <td>Sporosarcina psychrophila DSM 3</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 3</td>\n",
       "      <td>https://mediadive.dsmz.de/taxonomy?level=speci...</td>\n",
       "      <td>['1', 'J22']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/1', 'https:...</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>\\r\\n        ATCC 23304, BCRC 11738, CCM 2117, ...</td>\n",
       "      <td>[{'media_title': '1: NUTRIENT AGAR', 'media_li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bacterium</td>\n",
       "      <td>Sporosarcina globispora DSM 4</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 4</td>\n",
       "      <td>https://mediadive.dsmz.de/taxonomy?level=speci...</td>\n",
       "      <td>['514', 'J22']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/514', 'http...</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>\\r\\n        ATCC 23301, CCM 2119, CCUG 7419, C...</td>\n",
       "      <td>[{'media_title': '514: BACTO MARINE BROTH (DIF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bacterium</td>\n",
       "      <td>Psychrobacillus insolitus DSM 5</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 5</td>\n",
       "      <td>https://mediadive.dsmz.de/taxonomy?level=speci...</td>\n",
       "      <td>['123']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/123']</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>\\r\\n        ATCC 23299, CCM 2175, CCUG 7420, ,...</td>\n",
       "      <td>[{'media_title': '123: MARINE AGAR', 'media_li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46237</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phage (phagum) DSM 117437</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 117437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['381']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/381']</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'media_title': '381: LB (Luria-Bertani) MEDI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46238</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phage (phagum) DSM 117679</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 117679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['92']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/92']</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'media_title': '92: TRYPTICASE SOY YEAST EXT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46239</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Phage (phagum) DSM 117680</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 117680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['92']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/92']</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'media_title': '92: TRYPTICASE SOY YEAST EXT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Staphylococcus epidermidis DSM 117681</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 117681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['92']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/92']</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'media_title': '92: TRYPTICASE SOY YEAST EXT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Staphylococcus epidermidis DSM 117682</td>\n",
       "      <td>https://mediadive.dsmz.de/strains/view/DSM 117682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['92']</td>\n",
       "      <td>['https://mediadive.dsmz.de/medium/92']</td>\n",
       "      <td>['https://www.dsmz.de/collection/catalogue/det...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'media_title': '92: TRYPTICASE SOY YEAST EXT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46242 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:50:01.304420Z",
     "start_time": "2024-05-31T13:50:01.012814Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df.to_csv('merged_dsmz_strains.csv', index=False)",
   "id": "cd37b9c389f72b2f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f21df3c043175af1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
